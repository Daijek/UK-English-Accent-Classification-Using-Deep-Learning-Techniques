{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Notebook for arranging the datasets, splitting into test and train and augmetation"
      ],
      "metadata": {
        "id": "5-JsSbYyoJnx"
      },
      "id": "5-JsSbYyoJnx"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### I suggest that to understand this notebook, it is worth taking note of the points below"
      ],
      "metadata": {
        "id": "8zlNic6TpVR2"
      },
      "id": "8zlNic6TpVR2"
    },
    {
      "cell_type": "markdown",
      "source": [
        "+ For the crowd sourced uk english datset, we merged the male and the female classes together manually\n",
        "+ For the LibriTTs-British dataset, the data was represented in multiple nested directories and so we brought everything to a single parent directory (See the dataset for more context: https://www.kaggle.com/datasets/oscarvl/libritts-british-accents)\n",
        "+ And finally the audiomentations library was used to augment the dataset\n",
        "+ We augmented the UK accents data but not the LibriTTs data we used the Libritts-British data for testing and fintuning but not training"
      ],
      "metadata": {
        "id": "_Te6nSaNod8o"
      },
      "id": "_Te6nSaNod8o"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Because manually joined the male and female accents in the crowdsourced UK accents dataset, this notebook is divided into to which are;\n",
        "#### (1) Arranging the Libritts dataset to have all the classes under a single sub directory\n",
        "#### (2) Splitting the crowd sourced UK accents dataset into train and test\n",
        "#### (2) Applying data augmentation to the train data of the crowd sourced UK accents data"
      ],
      "metadata": {
        "id": "sYMz2TdYrAJ1"
      },
      "id": "sYMz2TdYrAJ1"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6EhofSnyq_hJ"
      },
      "id": "6EhofSnyq_hJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing the audiomentations library"
      ],
      "metadata": {
        "id": "FiZIQ6B4vxrO"
      },
      "id": "FiZIQ6B4vxrO"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58d3dbdc",
      "metadata": {
        "id": "58d3dbdc",
        "outputId": "3d69a441-954f-4a61-fadc-e728db55f449"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting audiomentations\n",
            "  Obtaining dependency information for audiomentations from https://files.pythonhosted.org/packages/be/0b/a7f3df0bc7625008933276103eaa008c388cc7848163fc562949b379b149/audiomentations-0.33.0-py3-none-any.whl.metadata\n",
            "  Downloading audiomentations-0.33.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy>=1.18.0 in c:\\users\\daniel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from audiomentations) (1.23.5)\n",
            "Requirement already satisfied: librosa!=0.10.0,<0.11.0,>=0.8.0 in c:\\users\\daniel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from audiomentations) (0.10.1)\n",
            "Requirement already satisfied: scipy<2,>=1.4.0 in c:\\users\\daniel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from audiomentations) (1.10.1)\n",
            "Requirement already satisfied: soxr<1.0.0,>=0.3.2 in c:\\users\\daniel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from audiomentations) (0.3.6)\n",
            "Requirement already satisfied: audioread>=2.1.9 in c:\\users\\daniel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (3.0.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\daniel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.14 in c:\\users\\daniel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (1.2.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\daniel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (5.1.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in c:\\users\\daniel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (0.58.0)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in c:\\users\\daniel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.0 in c:\\users\\daniel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (1.7.0)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in c:\\users\\daniel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (4.5.0)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in c:\\users\\daniel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (0.3)\n",
            "Requirement already satisfied: msgpack>=1.0 in c:\\users\\daniel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (1.0.7)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in c:\\users\\daniel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from numba>=0.51.0->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (0.41.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\daniel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pooch>=1.0->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (3.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\daniel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pooch>=1.0->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (23.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in c:\\users\\daniel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pooch>=1.0->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (2.31.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\daniel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn>=0.20.0->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in c:\\users\\daniel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from soundfile>=0.12.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (1.15.1)\n",
            "Requirement already satisfied: pycparser in c:\\users\\daniel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (2.21)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\daniel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (3.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\daniel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\daniel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\daniel\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa!=0.10.0,<0.11.0,>=0.8.0->audiomentations) (2023.5.7)\n",
            "Downloading audiomentations-0.33.0-py3-none-any.whl (76 kB)\n",
            "   ---------------------------------------- 0.0/76.8 kB ? eta -:--:--\n",
            "   ---------------------------------------- 76.8/76.8 kB 1.4 MB/s eta 0:00:00\n",
            "Installing collected packages: audiomentations\n",
            "Successfully installed audiomentations-0.33.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "! pip install audiomentations"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Importing the important libraries"
      ],
      "metadata": {
        "id": "di5kY6_WpjLm"
      },
      "id": "di5kY6_WpjLm"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e991f76b",
      "metadata": {
        "id": "e991f76b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "import random\n",
        "import shutil\n",
        "from audiomentations import AddBackgroundNoise, PolarityInversion, Compose, AddGaussianNoise, PitchShift, HighPassFilter"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br />\n",
        "<br />\n",
        "<br />\n"
      ],
      "metadata": {
        "id": "dO52VF7xuuSk"
      },
      "id": "dO52VF7xuuSk"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 1: Arranging the LibriTTs dataset to have all the classes under a single parent directory"
      ],
      "metadata": {
        "id": "Sl4tU82Qq8RD"
      },
      "id": "Sl4tU82Qq8RD"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining the path to the Libritts Dataset"
      ],
      "metadata": {
        "id": "4NFaj_JPqbLW"
      },
      "id": "4NFaj_JPqbLW"
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = \"archive\""
      ],
      "metadata": {
        "id": "lJfwtr2rqinQ"
      },
      "id": "lJfwtr2rqinQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Moving all the information in subdirectories for the LiBritts dataset to the parent directories"
      ],
      "metadata": {
        "id": "liwQic9hslMO"
      },
      "id": "liwQic9hslMO"
    },
    {
      "cell_type": "code",
      "source": [
        "for sub_parent_directory in os.listdir(data_dir):\n",
        "    parent_directory = f\"{data_dir}/{sub_parent_directory}\"\n",
        "    for foldername, subfolders, filenames in os.walk(parent_directory):\n",
        "        for filename in filenames:\n",
        "            # Build the full path for the file\n",
        "            file_path = f\"{foldername}/{filename}\"\n",
        "\n",
        "            if f\"{file_path.split('/')[-3]}/{file_path.split('/')[-2]}\" != parent_directory:\n",
        "                #Move the file to the parent directory\n",
        "                shutil.move(file_path, parent_directory)"
      ],
      "metadata": {
        "id": "CiqL1eBwskle"
      },
      "id": "CiqL1eBwskle",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Now that the sub directories are empty, delete the sub directories"
      ],
      "metadata": {
        "id": "ekWvcOJLqbId"
      },
      "id": "ekWvcOJLqbId"
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove all subdirectories in the parent directory\n",
        "for sub_parent_directory in os.listdir(data_dir):\n",
        "    parent_directory = f\"{data_dir}/{sub_parent_directory}\"\n",
        "    for foldername in os.listdir(parent_directory):\n",
        "        folder_path = os.path.join(parent_directory, foldername)\n",
        "        if os.path.isdir(folder_path):\n",
        "            shutil.rmtree(folder_path)"
      ],
      "metadata": {
        "id": "9RBlDr8TqshN"
      },
      "id": "9RBlDr8TqshN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Finally, we are only intrested in the accent data which are wav files, so we remove all files from the directories that are not WAV"
      ],
      "metadata": {
        "id": "7qm59CfiqbFl"
      },
      "id": "7qm59CfiqbFl"
    },
    {
      "cell_type": "code",
      "source": [
        "for sub_parent_directory in os.listdir(data_dir):\n",
        "    sub_parent_directory = f\"{data_dir}/{sub_parent_directory}\"\n",
        "    for directory in os.listdir(sub_parent_directory):\n",
        "        file_path = f\"{sub_parent_directory}/{directory}\"\n",
        "\n",
        "        if file_path.lower().endswith(\".wav\"):\n",
        "            pass\n",
        "        else:\n",
        "            # Remove non-WAV files\n",
        "            os.remove(file_path)"
      ],
      "metadata": {
        "id": "ZNNv7Y7GqtXK"
      },
      "id": "ZNNv7Y7GqtXK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we visualize the directories and they are now just 4 directories with our desired classes"
      ],
      "metadata": {
        "id": "J3YtSnqgqbCl"
      },
      "id": "J3YtSnqgqbCl"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7c73f927",
        "outputId": "c83dfcad-c14b-4363-c108-7bb1bfbdcacb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['libritts-english', 'libritts-irish', 'libritts-scottish', 'libritts-welsh']"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "os.listdir(\"archive\")"
      ],
      "id": "7c73f927"
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br />\n",
        "<br />\n",
        "<br />\n",
        "<br />\n",
        "<br />"
      ],
      "metadata": {
        "id": "31FJdOLsusO2"
      },
      "id": "31FJdOLsusO2"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 2: Splitting the crowd sourced UK accent dataset into train and test (80: 20)"
      ],
      "metadata": {
        "id": "CI5UZsV1tgPW"
      },
      "id": "CI5UZsV1tgPW"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining the paths to the test an train data\n"
      ],
      "metadata": {
        "id": "MyhN9F8btgKO"
      },
      "id": "MyhN9F8btgKO"
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = \"Data/train\"\n",
        "test_dir = \"Data/test\""
      ],
      "metadata": {
        "id": "2KeShfoctsuP"
      },
      "id": "2KeShfoctsuP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a function that would take 20% of the specified data directory and move it to the specified test directory randomly"
      ],
      "metadata": {
        "id": "AgdTNGl-tgHO"
      },
      "id": "AgdTNGl-tgHO"
    },
    {
      "cell_type": "code",
      "source": [
        "def move_20_percent_to_test(data_dir, test_dir, current_class):\n",
        "    number_of_images = len(os.listdir(f\"{data_dir}/{current_class}\"))\n",
        "    twenty_percent = int((20/100) * number_of_images)\n",
        "    files_to_move = []\n",
        "\n",
        "    images_to_move = []\n",
        "    while len(images_to_move) < twenty_percent:\n",
        "        random_image = random.randint(0, number_of_images - 1)\n",
        "\n",
        "        if random_image not in images_to_move:\n",
        "            images_to_move.append(random_image)\n",
        "\n",
        "    for img_file in images_to_move:\n",
        "        files_to_move.append(os.listdir(f\"{data_dir}/{current_class}\")[img_file])\n",
        "\n",
        "    for image_name in files_to_move:\n",
        "        shutil.move(f\"{data_dir}/{current_class}/{image_name}\", f\"{test_dir}/{current_class}\")"
      ],
      "metadata": {
        "id": "90H0vzAOtvTe"
      },
      "id": "90H0vzAOtvTe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Creating a the test directory for each class"
      ],
      "metadata": {
        "id": "YgDaIVNktwXO"
      },
      "id": "YgDaIVNktwXO"
    },
    {
      "cell_type": "code",
      "source": [
        "for current_class in os.listdir(train_dir):\n",
        "    os.mkdir(f\"{test_dir}/{current_class}\")"
      ],
      "metadata": {
        "id": "zANhSAkQt1Wv"
      },
      "id": "zANhSAkQt1Wv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the move_20_percent_method to move 20% of each class to the test directoriess created"
      ],
      "metadata": {
        "id": "sTZ5fRKTtwUt"
      },
      "id": "sTZ5fRKTtwUt"
    },
    {
      "cell_type": "code",
      "source": [
        "for current_class in os.listdir(train_dir):\n",
        "    move_20_percent_to_test(train_dir, test_dir, current_class)"
      ],
      "metadata": {
        "id": "HYriM2hHuLi5"
      },
      "id": "HYriM2hHuLi5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br />\n",
        "<br />\n",
        "<br />\n",
        "<br />\n",
        "<br />"
      ],
      "metadata": {
        "id": "l50gd3QGumhz"
      },
      "id": "l50gd3QGumhz"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 3: Augmenting the crowd sourced UK Accent data"
      ],
      "metadata": {
        "id": "hJlLuj_2ub_W"
      },
      "id": "hJlLuj_2ub_W"
    },
    {
      "cell_type": "markdown",
      "id": "d9274254",
      "metadata": {
        "id": "d9274254"
      },
      "source": [
        "### The \"audio_data_augmentation\" class\n",
        "#### This class is designed to carry out different augmentations on audio samples in a specified directory\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3752ff7f",
      "metadata": {
        "id": "3752ff7f"
      },
      "source": [
        "#### About the \"audio_data_augmentation\" class\n",
        "(1) This class is instantiated with 3 parameters which are the path to the audio, the path to the background noises to be added and the path where the augmented audio samples would be stored <br />\n",
        "(2) The methods of the class include the add_noises, the pitch_shift, the high_pass_filter, the pick_background_noise, the random_augment and the augment_samples"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6fe25929",
      "metadata": {
        "id": "6fe25929"
      },
      "source": [
        "#### About the  \"audio_data_augmentation\" class methods\n",
        "<h4 style=\"text-decoration: underline;\">(1) add_noises</h4>\n",
        "<p> The add_noises method randomly selects between guassian noise and one of the background noises in the background noise directory with probabilities of 0.2 and 0.8 respectively</p>\n",
        "<p> The method takes one parameter which is defines the probability of the selected noise beign applied to an audio sample</p>\n",
        "\n",
        "<h4 style=\"text-decoration: underline;\">(2) pitch_shift</h4>\n",
        "<p> The pitch shift method applies a shift in pitch which can either be higher or lower. It also calls the add_noises method with a probability of 0.4 which implies that when ever the pitchshift method is called to augment an audio, there is a 40% chance that noise would also be applied</p>\n",
        "\n",
        "<h4 style=\"text-decoration: underline;\">(3) high_pass_filter</h4>\n",
        "<p> This method filters audio sample by cutting off frequencies lower than 2000 and higher than 4000.</p>\n",
        "\n",
        "<h4 style=\"text-decoration: underline;\">(4) pick_background_noise</h4>\n",
        "<p> This method calls the add_noise method to augment an audio with either gaussian noise or recorded background noise. It uses a probability of 1 which implies that what ever noise that is selected would definately be added to the audio sample</p>\n",
        "\n",
        "<h4 style=\"text-decoration: underline;\">(5) random_augment</h4>\n",
        "<p> This method calls one of the aument methods randomly using specified probabilities</p>\n",
        "\n",
        "<h4 style=\"text-decoration: underline;\">(6) augment_samples</h4>\n",
        "<p> This method applies a specified augmentation to the audio samples in the directory with the audios</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "173ec859",
      "metadata": {
        "id": "173ec859"
      },
      "outputs": [],
      "source": [
        "class audio_data_augmentation():\n",
        "    def __init__(self, audio_path, aug_path, background_noises):\n",
        "        self.audio_path = audio_path\n",
        "        self.aug_path = aug_path\n",
        "        self.background_noises = background_noises\n",
        "\n",
        "    def add_noises(self, p = 1):\n",
        "        # (1) Create a list to hold objects for holding background noise and guassian noise respectively\n",
        "        Noises = [\n",
        "            AddBackgroundNoise(sounds_path = self.background_noises,\n",
        "                               min_snr_in_db = 3.0, max_snr_in_db = 20.0,\n",
        "                               noise_transform = PolarityInversion(),p = p),\n",
        "\n",
        "            AddGaussianNoise(min_amplitude=0.1, max_amplitude=0.2, p = p)\n",
        "        ]\n",
        "\n",
        "        # (2) Randomly picking between background noise and guassian noise with probabilities of 0.8 and 0.2 respectively\n",
        "        choice = random.choices(Noises, weights = [0.8, 0.2], k = 1)[0]\n",
        "        return choice\n",
        "\n",
        "    def pitch_shift(self):\n",
        "        return Compose([self.add_noises(p = 0.4),PitchShift(min_semitones = -8, max_semitones = 8, p = 1)])\n",
        "\n",
        "    def high_pass_filter(self):\n",
        "        return Compose([HighPassFilter(min_cutoff_freq = 2000, max_cutoff_freq = 4000, p = 1)])\n",
        "\n",
        "    def pick_background_noise(self):\n",
        "        return Compose([self.add_noises(p = 1)])\n",
        "\n",
        "    def random_augment(self):\n",
        "        return random.choices([self.pitch_shift(),\n",
        "                               self.high_pass_filter(),\n",
        "                               self.pick_background_noise()], weights = [0.05, 0.05, 0.9], k=1)[0]\n",
        "\n",
        "    def augment_samples(self, directory, aug_technique, aug_per_sample = 1):\n",
        "        for audio in os.listdir(f\"{self.audio_path}/{directory}\"):\n",
        "            for i in range(aug_per_sample):\n",
        "                signal, sr = librosa.load(f\"{self.audio_path}/{directory}/{audio}\", sr = 22050)\n",
        "                augmented_signal = aug_technique(signal, sr)\n",
        "                sf.write(f\"{self.aug_path}/{directory}/aug_{i}_{audio}\", augmented_signal, sr)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea7da473",
      "metadata": {
        "id": "ea7da473"
      },
      "source": [
        "### Testing the class"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c4e42cf",
      "metadata": {
        "id": "0c4e42cf"
      },
      "source": [
        "#### Creating a variable to hold the path to a random audio for testing purposes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b21bbda4",
      "metadata": {
        "scrolled": true,
        "id": "b21bbda4"
      },
      "outputs": [],
      "source": [
        "test_path = \"aug_test/test_train\"\n",
        "test_aug_path = \"aug_test/test_augmented_train\"\n",
        "test_dir = \"southern\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65be39f6",
      "metadata": {
        "id": "65be39f6"
      },
      "source": [
        "#### Creating a variable to hold the directory with the recorded background noises to be added"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ef279ce",
      "metadata": {
        "id": "6ef279ce"
      },
      "outputs": [],
      "source": [
        "background_noises_dir = \"background_noise\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d293aed4",
      "metadata": {
        "id": "d293aed4"
      },
      "outputs": [],
      "source": [
        "instance_to_test_class = audio_data_augmentation(test_path, test_aug_path, background_noises_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ef86db9",
      "metadata": {
        "id": "3ef86db9"
      },
      "outputs": [],
      "source": [
        "instance_to_test_class.augment_samples(test_dir, instance_to_test_class.random_augment())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a1452bb",
      "metadata": {
        "id": "5a1452bb"
      },
      "source": [
        "##### The test was successful in creating augmented versions of the audio samples Now I proceeded to using the class to augment the samples in the dataset\n",
        "<br /><br /><br /><br />"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5c9135e",
      "metadata": {
        "id": "d5c9135e"
      },
      "source": [
        "## Augmenting the UK accent dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7231d0be",
      "metadata": {
        "id": "7231d0be"
      },
      "source": [
        "#### Creating a list that stores to hold the directory names for the accents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd3481eb",
      "metadata": {
        "id": "dd3481eb",
        "outputId": "2bbb97ac-c490-490e-f4e3-454f5cef8407"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['irish', 'midlands', 'northern', 'scottish', 'southern', 'welsh']"
            ]
          },
          "execution_count": 347,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "accent_directories = os.listdir(\"Data/augmented_train\")\n",
        "accent_directories"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73926cc9",
      "metadata": {
        "id": "73926cc9"
      },
      "source": [
        "#### Defining the paths to the data to augment and where the augmented data should reside"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43bf9f3b",
      "metadata": {
        "id": "43bf9f3b"
      },
      "outputs": [],
      "source": [
        "train_data_path = \"Data/train\"\n",
        "aug_data_path = \"Data/augmented_train\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68d75ba9",
      "metadata": {
        "id": "68d75ba9"
      },
      "source": [
        "#### Creating an istance of the \"audio_data_augmentation\" class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d076f38",
      "metadata": {
        "id": "6d076f38"
      },
      "outputs": [],
      "source": [
        "augment_uk_accent_data = audio_data_augmentation(train_data_path, aug_data_path, background_noises_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bbc74595",
      "metadata": {
        "id": "bbc74595"
      },
      "source": [
        "#### calling the \"augment_samples\" method to create a randomly augmented version for the uk accent data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69b08d26",
      "metadata": {
        "id": "69b08d26"
      },
      "outputs": [],
      "source": [
        "for accent_directory in accent_directories:\n",
        "    augment_uk_accent_data.augment_samples(accent_directory, augment_uk_accent_data.random_augment())"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}